# lmms-eval Integration for Enhanced Model Evaluation

### Quick Start

```bash
# Evaluate a trained model on multiple benchmarks
python evaluation.py --model lusxvr/nanoVLM-222M --tasks mmstar,mme,gqa
```

### Training Integration

TODO:
Enable lmms-eval during training by modifying your `TrainConfig`:

```python
TODO
```

## Acknowledgments

This integration builds upon the excellent work of the [lmms-eval](https://github.com/EvolvingLMMs-Lab/lmms-eval) project, which provides a unified framework for evaluating large multi-modal models.
