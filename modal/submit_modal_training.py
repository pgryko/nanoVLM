#!/usr/bin/env python3
"""
Submit NanoVLM training job to Modal.com

This script provides a convenient interface to submit training jobs to Modal
with various configuration options.
"""

import argparse
import json
import os
import sys


def validate_dataset(dataset_path: str) -> bool:
    """Validate that the dataset file exists and has correct format"""
    if not os.path.exists(dataset_path):
        print(f"‚ùå Dataset file not found: {dataset_path}")
        return False

    try:
        with open(dataset_path, "r") as f:
            data = json.load(f)

        if not isinstance(data, list):
            print("‚ùå Dataset must be a JSON list")
            return False

        if len(data) == 0:
            print("‚ùå Dataset is empty")
            return False

        # Check first item structure
        first_item = data[0]
        required_keys = ["conversations"]

        if "image_path" in first_item:
            print("‚úÖ Single-image dataset format detected")
        elif "image_paths" in first_item:
            print("‚úÖ Multi-image dataset format detected")
        else:
            print("‚ùå Dataset must have either 'image_path' or 'image_paths' field")
            return False

        if "conversations" not in first_item:
            print("‚ùå Dataset must have 'conversations' field")
            return False

        print(f"‚úÖ Dataset validated: {len(data)} samples")
        return True

    except json.JSONDecodeError:
        print("‚ùå Invalid JSON format")
        return False
    except Exception as e:
        print(f"‚ùå Dataset validation error: {e}")
        return False


def submit_training_job(args):
    """Submit training job to Modal"""

    # Validate dataset
    if not validate_dataset(args.custom_dataset_path):
        return False

    # Validate HuggingFace options
    if args.push_to_hub and not args.hub_model_id:
        print("‚ùå --hub_model_id is required when using --push_to_hub")
        print("   Example: --hub_model_id pgryko/my-nanovlm-model")
        return False

    # Check if Modal is available
    try:
        import modal
    except ImportError:
        print("‚ùå Modal not installed. Install with: uv add modal")
        return False

    # Import the Modal app
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from modal_app import app, train_nanovlm

    print("üöÄ Submitting NanoVLM training job to Modal.com")
    print(f"Dataset: {args.custom_dataset_path}")
    print(
        f"Batch Size: {args.batch_size} (effective: {args.batch_size * args.gradient_accumulation_steps})"
    )
    print(f"Training Steps: {args.max_training_steps}")
    print(f"Expected Duration: ~{args.max_training_steps // 100} minutes")

    # For now, we'll pass the dataset content directly to avoid upload issues
    # In a production setup, you'd want to upload large datasets to Modal volumes
    dataset_path = args.custom_dataset_path
    if not os.path.exists(dataset_path):
        print(f"‚ùå Dataset file not found: {dataset_path}")
        return False

    # Read dataset content to pass to Modal
    with open(dataset_path, "r") as f:
        dataset_content = f.read()

    print("üì§ Preparing dataset for Modal training...")

    # Prepare training arguments
    training_kwargs = {
        "dataset_content": dataset_content,
        "batch_size": args.batch_size,
        "gradient_accumulation_steps": args.gradient_accumulation_steps,
        "max_training_steps": args.max_training_steps,
        "eval_interval": args.eval_interval,
        "lr_mp": args.lr_mp,
        "lr_backbones": args.lr_backbones,
        "wandb_project": args.wandb_project,
        "multi_image": args.multi_image,
        "compile_model": args.compile,
        "push_to_hub": args.push_to_hub,
        "hub_model_id": args.hub_model_id,
        "hub_private": args.hub_private,
    }

    if args.wandb_entity:
        training_kwargs["wandb_entity"] = args.wandb_entity

    if args.image_root_dir:
        training_kwargs["image_root_dir"] = args.image_root_dir

    # Submit training job
    try:
        print("üéØ Starting training on Modal...")
        with app.run():
            result = train_nanovlm.remote(**training_kwargs)
            print(f"‚úÖ Training completed! Model saved to: {result}")
            return True
    except Exception as e:
        print(f"‚ùå Training failed: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Submit NanoVLM training job to Modal.com",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    # Dataset arguments
    parser.add_argument(
        "--custom_dataset_path",
        type=str,
        required=True,
        help="Path to JSON file containing custom dataset",
    )
    parser.add_argument(
        "--image_root_dir",
        type=str,
        help="Root directory for images (if paths in JSON are relative)",
    )
    parser.add_argument(
        "--multi_image", action="store_true", help="Use multi-image dataset format"
    )

    # Training hyperparameters
    parser.add_argument(
        "--batch_size", type=int, default=8, help="Training batch size per GPU"
    )
    parser.add_argument(
        "--gradient_accumulation_steps",
        type=int,
        default=4,
        help="Number of gradient accumulation steps",
    )
    parser.add_argument(
        "--max_training_steps",
        type=int,
        default=2000,
        help="Maximum number of training steps",
    )
    parser.add_argument(
        "--eval_interval",
        type=int,
        default=200,
        help="Evaluation and checkpoint saving interval",
    )
    parser.add_argument(
        "--lr_mp",
        type=float,
        default=0.00512,
        help="Learning rate for the modality projector",
    )
    parser.add_argument(
        "--lr_backbones",
        type=float,
        default=5e-5,
        help="Learning rate for vision and language backbones",
    )

    # Model options
    parser.add_argument(
        "--compile",
        action="store_true",
        help="Use torch.compile for model optimization",
    )

    # HuggingFace options
    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Push trained model to HuggingFace Hub",
    )
    parser.add_argument(
        "--hub_model_id",
        type=str,
        help="HuggingFace model ID (e.g., 'username/model-name')",
    )
    parser.add_argument(
        "--hub_private", action="store_true", help="Make HuggingFace repository private"
    )

    # Logging options
    parser.add_argument(
        "--wandb_entity", type=str, help="Weights & Biases entity (username or team)"
    )
    parser.add_argument(
        "--wandb_project",
        type=str,
        default="nanovlm-modal",
        help="Weights & Biases project name",
    )

    # Utility commands
    parser.add_argument(
        "--list_checkpoints",
        action="store_true",
        help="List available model checkpoints",
    )

    args = parser.parse_args()

    # Handle utility commands
    if args.list_checkpoints:
        try:
            sys.path.append(os.path.dirname(os.path.abspath(__file__)))
            from modal_app import app, list_checkpoints

            with app.run():
                list_checkpoints.remote()
        except Exception as e:
            print(f"‚ùå Failed to list checkpoints: {e}")
        return

    # Submit training job
    success = submit_training_job(args)
    if not success:
        sys.exit(1)

    print("\nüéâ Training job submitted successfully!")
    print("\nüìä Monitor your training:")
    if args.wandb_entity:
        print(f"   W&B: https://wandb.ai/{args.wandb_entity}/{args.wandb_project}")
    print("   Modal: https://modal.com/apps")

    print("\nüìÅ Access your trained model:")
    print("   Run: python modal/submit_modal_training.py --list_checkpoints")


if __name__ == "__main__":
    main()
