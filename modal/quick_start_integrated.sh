#!/bin/bash
# Quick start script for integrated dataset building + training on Modal.com

set -e

echo "üöÄ NanoVLM Integrated Training on Modal.com"
echo "============================================="

# Check if Modal is installed
if ! command -v modal &> /dev/null; then
    echo "‚ùå Modal not found. Installing..."
    uv add modal
fi

# Check if user is authenticated
if modal token list &> /dev/null; then
    echo "‚úÖ Modal authentication verified"
else
    echo "üîê Setting up Modal authentication..."
    modal setup
fi

echo ""
echo "üéØ Starting integrated dataset building + training..."
echo ""

# Default configuration for quick start
DATASET_TYPE="mixed"
DATASET_LIMIT=10000
BATCH_SIZE=8
MAX_TRAINING_STEPS=3000
WANDB_ENTITY="piotr-gryko-devalogic"
HUB_MODEL_ID="pgryko/nanovlm-COCO-VQAv2"

echo "Configuration:"
echo "  Dataset: $DATASET_TYPE ($DATASET_LIMIT samples)"
echo "  Batch size: $BATCH_SIZE"
echo "  Training steps: $MAX_TRAINING_STEPS"
echo "  W&B entity: $WANDB_ENTITY"
echo "  Hub model ID: $HUB_MODEL_ID"
echo ""

# Submit the integrated job
uv run python modal/submit_modal_training.py \
  --build_dataset \
  --dataset_type "$DATASET_TYPE" \
  --dataset_limit "$DATASET_LIMIT" \
  --batch_size "$BATCH_SIZE" \
  --max_training_steps "$MAX_TRAINING_STEPS" \
  --compile \
  --wandb_entity "$WANDB_ENTITY" \
  --push_to_hub \
  --hub_model_id "$HUB_MODEL_ID"

echo ""
echo "‚úÖ Training job submitted!"
echo ""
echo "üìä Monitor your training:"
echo "   W&B: https://wandb.ai/$WANDB_ENTITY/nanovlm-modal"
echo "   Modal: https://modal.com/apps"
echo ""
echo "ü§ó Your model will be available at:"
echo "   https://huggingface.co/$HUB_MODEL_ID"
echo ""
echo "üìù Features included:"
echo "   ‚úÖ Automatic dataset building on Modal"
echo "   ‚úÖ Comprehensive model card generation"
echo "   ‚úÖ Training configuration documentation"
echo "   ‚úÖ Usage examples and code snippets"
echo "   ‚úÖ Performance metrics and monitoring links"
